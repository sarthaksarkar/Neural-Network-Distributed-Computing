{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import threading\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def derrelu(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "def tanh(x):\n",
    "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "def dertanh(x):\n",
    "    return 1-np.power(np.tanh(x),2)\n",
    "def sig(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1/(1+np.exp(-x))\n",
    "def softmax(x):\n",
    "    expX = np.exp(x)\n",
    "    return expX/np.sum(expX, axis = 1,keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeparameters_class(n0,n1,n2):\n",
    "    W1=np.random.random((n1,n0))\n",
    "    B1 = np.zeros((n1, 1))\n",
    "    W2=np.random.random((n2,n1))\n",
    "    B2 = np.zeros((n2, 1))\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def forwardpropogation_class(X,parameters):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=(np.dot(W1,X.T)+B1).T\n",
    "    A1=relu(Z1)\n",
    "    Z2=(np.dot(W2,A1.T)+B2).T\n",
    "    A2=sig(Z2)\n",
    "    A2 = np.clip(A2, 1e-10, 1 - 1e-10)\n",
    "    A2 = np.nan_to_num(A2, nan=1e-10)\n",
    "    forward_cache={\n",
    "        'Z1' :Z1,\n",
    "        'A1' :A1,\n",
    "        'Z2' :Z2,\n",
    "        'A2' :A2\n",
    "\n",
    "    }\n",
    "    return forward_cache\n",
    "def costfunction_class(Y,A2):\n",
    "    m=Y.shape[0]\n",
    "    cost = -(1/m)*np.sum(Y*np.log(A2)+(1-Y)*np.log(1-A2))\n",
    "    return cost\n",
    "def backwardpropagation_class(X,Y,parameters,forward_cache):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=forward_cache['Z1']\n",
    "    A1=forward_cache['A1']\n",
    "    Z2=forward_cache['Z2']\n",
    "    A2=forward_cache['A2']\n",
    "    m=Y.shape[0]\n",
    "    dZ2=A2-Y\n",
    "    dW2=(1/m)*np.dot(dZ2.T,A1)\n",
    "    dB2=(1/m)*np.sum(dZ2,axis=0,keepdims=True).T\n",
    "    dA1=np.dot(dZ2,W2)\n",
    "    dZ1=dA1*derrelu(Z1)\n",
    "    dW1=(1/m)*np.dot(dZ1.T,X)\n",
    "    dB1=(1/m)*np.sum(dZ1,axis=0,keepdims=True).T\n",
    "    gradients={\n",
    "        'dW1' :dW1,\n",
    "        'dB1' :dB1,\n",
    "        'dW2' :dW2,\n",
    "        'dB2' :dB2\n",
    "    }\n",
    "    return gradients\n",
    "def updateparameters_class(parameters,gradients,learningrate):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    dW1=gradients['dW1']\n",
    "    dW2=gradients['dW2']\n",
    "    dB1=gradients['dB1']\n",
    "    dB2=gradients['dB2']\n",
    "    W1-=learningrate*dW1\n",
    "    B1-=learningrate*dB1\n",
    "    W2-=learningrate*dW2\n",
    "    B2-=learningrate*dB2\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def model_class(X,Y,n1,learningrate,iterations):\n",
    "    n0=X.shape[1]\n",
    "    n2=Y.shape[1]\n",
    "    costlist=[]\n",
    "    parameters=initializeparameters_class(n0,n1,n2)\n",
    "    for i in range(iterations):\n",
    "        forward_cache=forwardpropogation_class(X,parameters)\n",
    "        cost=costfunction_class(Y,forward_cache['A2'])\n",
    "        gradients=backwardpropagation_class(X,Y,parameters,forward_cache)\n",
    "        parameters=updateparameters_class(parameters,gradients,learningrate)\n",
    "        if(i%(iterations/10)==0):\n",
    "            costlist.append(cost)\n",
    "    return parameters,costlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the model for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeparameters_mulclass(n0,n1,n2):\n",
    "    W1 = np.random.randn(n1, n0)*0.01\n",
    "    B1 = np.zeros((n1, 1))\n",
    "    \n",
    "    W2 = np.random.randn(n2, n1)*0.01\n",
    "    B2 = np.zeros((n2, 1))\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def forwardpropogation_mulclass(X,parameters):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=(np.dot(W1,X.T)+B1).T\n",
    "    A1=tanh(Z1)\n",
    "    Z2=(np.dot(W2,A1.T)+B2).T\n",
    "    A2=softmax(Z2)\n",
    "    forward_cache={\n",
    "        'Z1' :Z1,\n",
    "        'A1' :A1,\n",
    "        'Z2' :Z2,\n",
    "        'A2' :A2\n",
    "\n",
    "    }\n",
    "    return forward_cache\n",
    "def costfunction_mulclass(Y,A2):\n",
    "    m=Y.shape[0]\n",
    "    cost = -(1/m)*np.sum(Y*np.log(A2))\n",
    "    return cost\n",
    "def backwardpropagation_mulclass(X,Y,parameters,forward_cache):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=forward_cache['Z1']\n",
    "    A1=forward_cache['A1']\n",
    "    Z2=forward_cache['Z2']\n",
    "    A2=forward_cache['A2']\n",
    "    m=Y.shape[0]\n",
    "    dZ2=A2-Y\n",
    "    dW2=(1/m)*np.dot(dZ2.T,A1)\n",
    "    dB2=(1/m)*np.sum(dZ2,axis=0,keepdims=True).T\n",
    "    dA1=np.dot(dZ2,W2)\n",
    "    dZ1=dA1*dertanh(Z1)\n",
    "    dW1=(1/m)*np.dot(dZ1.T,X)\n",
    "    dB1=(1/m)*np.sum(dZ1,axis=0,keepdims=True).T\n",
    "    gradients={\n",
    "        'dW1' :dW1,\n",
    "        'dB1' :dB1,\n",
    "        'dW2' :dW2,\n",
    "        'dB2' :dB2\n",
    "    }\n",
    "    return gradients\n",
    "def updateparameters_mulclass(parameters,gradients,learningrate):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    dW1=gradients['dW1']\n",
    "    dW2=gradients['dW2']\n",
    "    dB1=gradients['dB1']\n",
    "    dB2=gradients['dB2']\n",
    "    W1-=learningrate*dW1\n",
    "    B1-=learningrate*dB1\n",
    "    W2-=learningrate*dW2\n",
    "    B2-=learningrate*dB2\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def model_mulclass(X,Y,n1,learningrate,iterations):\n",
    "    n0=X.shape[1]\n",
    "    n2=Y.shape[1]\n",
    "    costlist=[]\n",
    "    parameters=initializeparameters_mulclass(n0,n1,n2)\n",
    "    for i in range(iterations):\n",
    "        forward_cache=forwardpropogation_mulclass(X,parameters)\n",
    "        cost=costfunction_mulclass(Y,forward_cache['A2'])\n",
    "        gradients=backwardpropagation_mulclass(X,Y,parameters,forward_cache)\n",
    "        parameters=updateparameters_mulclass(parameters,gradients,learningrate)\n",
    "        if(i%(iterations/10)==0):\n",
    "            costlist.append(cost)\n",
    "    return parameters,costlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the model for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeparameters_reg(n0,n1,n2):\n",
    "    W1 = np.random.randn(n1, n0)*0.01\n",
    "    B1 = np.zeros((n1, 1))\n",
    "    \n",
    "    W2 = np.random.randn(n2, n1)*0.01\n",
    "    B2 = np.zeros((n2, 1))\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def forwardpropogation_reg(X,parameters):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=(np.dot(W1,X.T)+B1).T\n",
    "    A1=tanh(Z1)\n",
    "    Z2=(np.dot(W2,A1.T)+B2).T\n",
    "    A2=Z2\n",
    "    forward_cache={\n",
    "        'Z1' :Z1,\n",
    "        'A1' :A1,\n",
    "        'Z2' :Z2,\n",
    "        'A2' :A2\n",
    "\n",
    "    }\n",
    "    return forward_cache\n",
    "def costfunction_reg(Y,A2):\n",
    "    m=Y.shape[0]\n",
    "    cost = (1/(2*m))*np.dot((A2-Y).T,(A2-Y))  \n",
    "    return cost\n",
    "def backwardpropagation_reg(X,Y,parameters,forward_cache):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    Z1=forward_cache['Z1']\n",
    "    A1=forward_cache['A1']\n",
    "    Z2=forward_cache['Z2']\n",
    "    A2=forward_cache['A2']\n",
    "    m=Y.shape[0]\n",
    "    dZ2=A2-Y\n",
    "    dW2=(1/m)*np.dot(dZ2.T,A1)\n",
    "    dB2=(1/m)*np.sum(dZ2,axis=0,keepdims=True).T\n",
    "    dA1=np.dot(dZ2,W2)\n",
    "    dZ1=dA1*dertanh(Z1)\n",
    "    dW1=(1/m)*np.dot(dZ1.T,X)\n",
    "    dB1=(1/m)*np.sum(dZ1,axis=0,keepdims=True).T\n",
    "    gradients={\n",
    "        'dW1' :dW1,\n",
    "        'dB1' :dB1,\n",
    "        'dW2' :dW2,\n",
    "        'dB2' :dB2\n",
    "    }\n",
    "    return gradients\n",
    "def updateparameters_reg(parameters,gradients,learningrate):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "    dW1=gradients['dW1']\n",
    "    dW2=gradients['dW2']\n",
    "    dB1=gradients['dB1']\n",
    "    dB2=gradients['dB2']\n",
    "    W1-=learningrate*dW1\n",
    "    B1-=learningrate*dB1\n",
    "    W2-=learningrate*dW2\n",
    "    B2-=learningrate*dB2\n",
    "    parameters={\n",
    "        'W1' :W1,\n",
    "        'B1' :B1,\n",
    "        'W2' :W2,\n",
    "        'B2' :B2\n",
    "    }\n",
    "    return parameters\n",
    "def model_reg(X,Y,n1,learningrate,iterations):\n",
    "    n0=X.shape[1]\n",
    "    n2=Y.shape[1]\n",
    "    costlist=[]\n",
    "    parameters=initializeparameters_reg(n0,n1,n2)\n",
    "    for i in range(iterations):\n",
    "        forward_cache=forwardpropogation_reg(X,parameters)\n",
    "        cost=costfunction_reg(Y,forward_cache['A2'])\n",
    "        gradients=backwardpropagation_reg(X,Y,parameters,forward_cache)\n",
    "        parameters=updateparameters_reg(parameters,gradients,learningrate)\n",
    "        if(i%(iterations/10)==0):\n",
    "            costlist.append(cost)\n",
    "    return parameters,costlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server is listening\n",
      "new connection  ('127.0.0.1', 46086)  connected\n",
      "active connections  7\n",
      "choice is  1\n",
      "W1 is [[-5.71650711e-03 -1.62063948e-02  1.10079359e-02]\n",
      " [-7.07720071e-03  2.58218888e-02  8.30990720e-03]\n",
      " [-2.16369175e-02 -1.31716747e-02 -3.56582048e-03]\n",
      " [ 5.23243224e-03 -8.19026325e-03 -2.27629863e-04]\n",
      " [ 2.50206702e-03 -1.03323800e-02 -2.76494045e-03]\n",
      " [-3.50413440e-03 -2.10240413e-03 -6.86742729e-03]\n",
      " [-8.61704804e-04 -1.48864990e-02 -7.68202685e-03]\n",
      " [ 6.25604426e-03  4.05658199e-03  5.09832483e-04]\n",
      " [-1.08936720e-02  2.75385896e-02 -5.06303520e-03]\n",
      " [-4.18485063e-03  7.34517532e-05 -1.73552908e-03]]\n",
      "Sending W2 with shape: (1, 10) and 80 bytes\n",
      "W2 is [[-0.00154063  0.0181255  -0.00305455 -0.00062765  0.0141691  -0.01064167\n",
      "  -0.02706617  0.00296441 -0.00542992 -0.01913398]]\n",
      "Sending B1 with shape: (10, 1) and 80 bytes\n",
      "B1 is [[-7.35319852e-05]\n",
      " [ 4.18013663e-03]\n",
      " [ 4.79721928e-05]\n",
      " [-8.38750014e-05]\n",
      " [ 3.96400991e-03]\n",
      " [-2.56137482e-03]\n",
      " [-6.62625578e-03]\n",
      " [ 5.36533769e-04]\n",
      " [-1.75685264e-03]\n",
      " [-4.91704976e-03]]\n",
      "Sending B2 with shape: (1, 1) and 8 bytes\n",
      "B2 is [[0.26598055]]\n",
      "the neurons are: 10\n",
      "the learning are: 0.01\n",
      "the number of iteration are: 100\n",
      "new connection  ('127.0.0.1', 51604)  connected\n",
      "active connections  7\n",
      "choice is  2\n",
      "W1 is [[ 0.98133369  0.76022586  0.73524822]\n",
      " [ 0.39408536  0.45907339  0.23447279]\n",
      " [ 0.91330809  0.03084116  0.95686264]\n",
      " [-0.11323231  0.1788607   0.56251942]\n",
      " [ 0.36975349  0.79782748  0.38591671]\n",
      " [ 0.49491242  0.2927931   0.42397798]\n",
      " [ 0.12449203  0.32674521  0.59493015]\n",
      " [ 0.86907965  0.31854282  0.19847494]\n",
      " [-0.06899569  0.57573787  0.35887796]\n",
      " [ 0.73114527  0.47014963  0.70152905]]\n",
      "Sending W2 with shape: (1, 10) and 80 bytes\n",
      "W2 is [[-0.3602981   0.2625924  -0.15169452  0.65214108  0.30350155 -0.21234216\n",
      "  -0.02773362 -0.19992707  0.74680836 -0.46801776]]\n",
      "Sending B1 with shape: (10, 1) and 80 bytes\n",
      "B1 is [[ 0.01903988]\n",
      " [-0.1831381 ]\n",
      " [-0.04024995]\n",
      " [-0.28487454]\n",
      " [-0.22604294]\n",
      " [ 0.02614801]\n",
      " [-0.04183203]\n",
      " [ 0.00356155]\n",
      " [-0.35686322]\n",
      " [ 0.10312765]]\n",
      "Sending B2 with shape: (1, 1) and 8 bytes\n",
      "B2 is [[-0.47142725]]\n",
      "the neurons are: 10\n",
      "the learning are: 0.01\n",
      "the number of iteration are: 100\n",
      "new connection  ('127.0.0.1', 58892)  connected\n",
      "active connections  7\n",
      "choice is  3\n",
      "W1 is [[ 0.00177627 -0.01809596 -0.00155115  0.0027568   0.0092855  -0.0101134\n",
      "   0.00083551]\n",
      " [-0.00401687  0.00277081  0.00111163 -0.01816111 -0.01059516 -0.00527418\n",
      "  -0.00206118]\n",
      " [-0.00107713 -0.01355508 -0.00823585  0.00868542  0.00234474 -0.00116415\n",
      "   0.00541714]\n",
      " [ 0.00015204  0.00853377  0.00188834  0.00457306 -0.01525607 -0.01243419\n",
      "  -0.00600278]\n",
      " [ 0.02722676  0.01179638  0.01679813 -0.00025712  0.0085259   0.02364853\n",
      "   0.01316621]\n",
      " [ 0.00286503 -0.01748767  0.00173341 -0.0032428  -0.00997883 -0.0154429\n",
      "   0.01432398]\n",
      " [ 0.00702442  0.00053038 -0.00801144 -0.01478296  0.00231621 -0.00713008\n",
      "  -0.0082692 ]\n",
      " [ 0.01674112 -0.00269307  0.00697777  0.01915061  0.00895575 -0.00119436\n",
      "  -0.02201977]\n",
      " [-0.01053798 -0.00021606 -0.01069426 -0.01488678 -0.00426549 -0.01528049\n",
      "  -0.01031978]\n",
      " [-0.00499751 -0.00998227  0.01887767  0.00100652  0.01777746  0.01917012\n",
      "   0.00103404]]\n",
      "Sending W2 with shape: (4, 10) and 320 bytes\n",
      "W2 is [[-0.00555894  0.01639834  0.00105603  0.00346485 -0.0085204   0.00744987\n",
      "  -0.00122758 -0.01085035  0.0187118  -0.01928521]\n",
      " [ 0.00578297  0.01816499  0.00142713 -0.0007261  -0.01624565  0.0353449\n",
      "  -0.0004586  -0.00208647  0.01044233  0.00398116]\n",
      " [-0.00697636  0.01063459 -0.00789029  0.00112387 -0.00762804 -0.00975062\n",
      "   0.01855392 -0.01916281  0.01281147 -0.01512785]\n",
      " [-0.00759063 -0.00268915  0.00146637  0.00438533 -0.01196958 -0.01179726\n",
      "  -0.00193091  0.00088484  0.02398076 -0.00928669]]\n",
      "Sending B1 with shape: (10, 1) and 80 bytes\n",
      "B1 is [[ 0.00440211]\n",
      " [-0.00820477]\n",
      " [ 0.00148319]\n",
      " [-0.00095634]\n",
      " [ 0.00500548]\n",
      " [-0.00332283]\n",
      " [-0.00191418]\n",
      " [ 0.00551084]\n",
      " [-0.01229338]\n",
      " [ 0.00687704]]\n",
      "Sending B2 with shape: (4, 1) and 32 bytes\n",
      "B2 is [[-0.24994429]\n",
      " [-0.24994723]\n",
      " [-0.25001171]\n",
      " [-0.25009677]]\n",
      "the neurons are: 10\n",
      "the learning are: 0.01\n",
      "the number of iteration are: 100\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import threading\n",
    "import numpy as np\n",
    "import struct\n",
    "host=socket.gethostbyname(socket.gethostname())\n",
    "port=5060\n",
    "server=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "server.bind((host,port))\n",
    "server.listen(4)\n",
    "print('server is listening')\n",
    "def handle_client(communication_socket,address):\n",
    "    print('new connection ',address,' connected')\n",
    "    shape_length_headerX = communication_socket.recv(10).decode('utf-8').strip()\n",
    "    shape_lengthX = int(shape_length_headerX)\n",
    "    shape_arrayX=communication_socket.recv(shape_lengthX).decode('utf-8')\n",
    "    shapeX = tuple(map(int, shape_arrayX.split(',')))\n",
    "    array_bitsX=communication_socket.recv(np.prod(shapeX) * 8)\n",
    "    X=np.frombuffer(array_bitsX,dtype=np.float64)\n",
    "    X=X.reshape(shapeX)\n",
    "    shape_length_headerY = communication_socket.recv(10).decode('utf-8').strip()\n",
    "    shape_lengthY = int(shape_length_headerY)\n",
    "    shape_arrayY=communication_socket.recv(shape_lengthY).decode('utf-8')\n",
    "    shapeY = tuple(map(int, shape_arrayY.split(',')))\n",
    "    array_bitsY=communication_socket.recv(np.prod(shapeY) * 8)\n",
    "    Y=np.frombuffer(array_bitsY,dtype=np.float64)\n",
    "    Y=Y.reshape(shapeY)\n",
    "    #start of machine learning\n",
    "    choice=communication_socket.recv(2040).decode('utf-8')\n",
    "    neurons = struct.unpack('i', communication_socket.recv(4))[0]\n",
    "    learning_rate = struct.unpack('d', communication_socket.recv(8))[0]\n",
    "    iter = struct.unpack('i', communication_socket.recv(4))[0]\n",
    "    print('choice is ',choice)\n",
    "    if choice=='1':\n",
    "        parameters,costlist=model_reg(X,Y,neurons,learning_rate,iter)\n",
    "    elif choice=='2':\n",
    "        parameters,costlist=model_class(X,Y,neurons,learning_rate,iter)\n",
    "    elif choice=='3':\n",
    "        parameters,costlist=model_mulclass(X,Y,neurons,learning_rate,iter)\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    B1=parameters['B1']\n",
    "    B2=parameters['B2']\n",
    "\n",
    "    array_shape = ','.join(map(str, W1.shape))\n",
    "    shape_length = str(len(array_shape)).ljust(10)\n",
    "    communication_socket.send(shape_length.encode('utf-8')) \n",
    "    communication_socket.send(array_shape.encode('utf-8'))\n",
    "    W1_bytes = W1.tobytes()\n",
    "    communication_socket.send(W1_bytes)\n",
    "    print('W1 is',W1)\n",
    "    \n",
    "    array_shape2 = ','.join(map(str, W2.shape))\n",
    "    shape_length2 = str(len(array_shape2)).ljust(10)\n",
    "    communication_socket.send(shape_length2.encode('utf-8'))  \n",
    "    communication_socket.send(array_shape2.encode('utf-8'))   \n",
    "\n",
    "\n",
    "    W2_float64 = W2.astype(np.float64)  \n",
    "    W2_bytes = W2_float64.tobytes()  \n",
    "\n",
    "    print(f'Sending W2 with shape: {W2.shape} and {len(W2_bytes)} bytes')\n",
    "    communication_socket.send(W2_bytes)  \n",
    "    print('W2 is',W2)\n",
    "    \n",
    "    array_shape3 = ','.join(map(str, B1.shape))\n",
    "    shape_length3 = str(len(array_shape3)).ljust(10)\n",
    "    communication_socket.send(shape_length3.encode('utf-8'))  \n",
    "    communication_socket.send(array_shape3.encode('utf-8'))  \n",
    "\n",
    "\n",
    "    B1_float64 = B1.astype(np.float64)  \n",
    "    B1_bytes = B1_float64.tobytes()  \n",
    "\n",
    "    print(f'Sending B1 with shape: {B1.shape} and {len(B1_bytes)} bytes')\n",
    "    communication_socket.send(B1_bytes)  \n",
    "    print('B1 is',B1)\n",
    "    \n",
    "    array_shape4 = ','.join(map(str, B2.shape))\n",
    "    shape_length4 = str(len(array_shape4)).ljust(10)\n",
    "    communication_socket.send(shape_length4.encode('utf-8'))  \n",
    "    communication_socket.send(array_shape4.encode('utf-8'))  \n",
    "\n",
    "\n",
    "    B2_float64 = B2.astype(np.float64)  \n",
    "    B2_bytes = B2_float64.tobytes()  \n",
    "\n",
    "    print(f'Sending B2 with shape: {B2.shape} and {len(B2_bytes)} bytes')\n",
    "    communication_socket.send(B2_bytes) \n",
    "    print('B2 is',B2)\n",
    "    \n",
    "    communication_socket.close()\n",
    "    print('the neurons are:',neurons)\n",
    "    print('the learning are:',learning_rate) \n",
    "    print('the number of iteration are:',iter)\n",
    "\n",
    "    \n",
    "while True:\n",
    "    communication_socket,address=server.accept()\n",
    "    thread=threading.Thread(target=handle_client,args=(communication_socket,address))\n",
    "    thread.start()\n",
    "    print('active connections ',threading.active_count()-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
